{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3de6eb1e-6dae-4151-a8d8-f6ab8ded2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file = \"thesaurus/DRZE/BETHES8_201209.xml\"\n",
    "dtd_file = \"thesaurus/DRZE/thesauri.dtd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67685375-b158-4c92-a115-78dd05cfb3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass 1: Collecting descriptor terms...\n",
      "Pass 2: Collecting synonyms...\n",
      "Pass 3: Collecting supergroup names...\n",
      "Pass 4: Mapping relationships...\n",
      "Final Assembly: Building the data and writing to thesaurus_by_supergroup.txt...\n",
      "Done. The output has been saved to the file.\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "from collections import defaultdict\n",
    "\n",
    "# This script parses the xml Thesaurus files and creates a synonym list file for each Supergroup (1-14)\n",
    "LANG_ID_ENGLISH = \"2\"\n",
    "#LANGID=1 corresponds to language: German\n",
    "#LANGID=2 corresponds to language: English\n",
    "#LANGID=3 corresponds to language: French\n",
    "output_filename = \"thesaurus_by_supergroup.txt\"\n",
    "\n",
    "# --- Data storage ---\n",
    "termid_to_keyword = {}\n",
    "keyword_synonyms = defaultdict(list)\n",
    "supergroup_names = {}\n",
    "descriptor_to_supergroups = defaultdict(list)\n",
    "descriptor_narrower_terms = defaultdict(list)\n",
    "\n",
    "# --- Pass 1: Collect keywords from DESCRIPTORS ---\n",
    "print(\"Pass 1: Collecting descriptor terms...\")\n",
    "for _, elem in etree.iterparse(xml_file, events=(\"end\",), tag=\"DESCRIPTOR\"):\n",
    "    termid = elem.get(\"TERMID\")\n",
    "    langdata = elem.find(f\"LANGDATA[@LANGID='{LANG_ID_ENGLISH}']\")\n",
    "    if langdata is not None:\n",
    "        term_elem = langdata.find(\"TERM\")\n",
    "        if term_elem is not None and term_elem.text:\n",
    "            keyword = term_elem.text.strip()\n",
    "            termid_to_keyword[termid] = keyword\n",
    "    elem.clear()\n",
    "\n",
    "# --- Pass 2: Collect synonyms from SYNONYMS ---\n",
    "print(\"Pass 2: Collecting synonyms...\")\n",
    "for _, elem in etree.iterparse(xml_file, events=(\"end\",), tag=\"SYNONYMS\"):\n",
    "    if elem.get(\"LANGID\") == LANG_ID_ENGLISH:\n",
    "        for synonym in elem.findall(\"SYNONYM\"):\n",
    "            useptr = synonym.findtext(\"USEPTR\")\n",
    "            term = synonym.findtext(\"TERM\")\n",
    "            if useptr and term:\n",
    "                keyword_synonyms[useptr.strip()].append(term.strip())\n",
    "    elem.clear()\n",
    "\n",
    "# --- Pass 3: Collect Supergroup names ---\n",
    "print(\"Pass 3: Collecting supergroup names...\")\n",
    "for _, elem in etree.iterparse(xml_file, events=(\"end\",), tag=\"SUPERGROUP\"):\n",
    "    sg_id = elem.get(\"ID\")\n",
    "    lang_entry = elem.find(f\"LANGENTRY[@LANGID='{LANG_ID_ENGLISH}']\")\n",
    "    if lang_entry is not None:\n",
    "        designator = lang_entry.findtext(\"DESIGNATOR\")\n",
    "        if designator:\n",
    "            supergroup_names[sg_id] = designator.strip()\n",
    "    elem.clear()\n",
    "\n",
    "# --- Pass 4: Map descriptors to supergroups and collect narrower terms ---\n",
    "print(\"Pass 4: Mapping relationships...\")\n",
    "for _, elem in etree.iterparse(xml_file, events=(\"end\",), tag=\"DESCRIPTOR\"):\n",
    "    termid = elem.get(\"TERMID\")\n",
    "    # Map to supergroups via GROUPPTR\n",
    "    for group_ptr in elem.findall(\"GROUPPTR\"):\n",
    "        if group_ptr.text:\n",
    "            sg_id = group_ptr.text.strip()\n",
    "            descriptor_to_supergroups[termid].append(sg_id)\n",
    "    # Collect narrower term IDs via NTPTR\n",
    "    for nt_ptr in elem.findall(\"NTPTR\"):\n",
    "        if nt_ptr.text:\n",
    "            narrower_term_id = nt_ptr.text.strip()\n",
    "            descriptor_narrower_terms[termid].append(narrower_term_id)\n",
    "    elem.clear()\n",
    "\n",
    "# --- Final Assembly and File Writing ---\n",
    "print(f\"Final Assembly: Building the data and writing to {output_filename}...\")\n",
    "supergroup_all_terms = defaultdict(list)\n",
    "\n",
    "# Iterate through all known descriptors\n",
    "for termid, keyword in termid_to_keyword.items():\n",
    "    # Collect all terms related to THIS descriptor in a single list\n",
    "    all_related_terms = []\n",
    "    all_related_terms.append(keyword)\n",
    "    all_related_terms.extend(keyword_synonyms.get(termid, []))\n",
    "    \n",
    "    # Look up this descriptor's narrower terms by ID, then convert those IDs to keywords\n",
    "    narrower_ids = descriptor_narrower_terms.get(termid, [])\n",
    "    narrower_keywords = [termid_to_keyword.get(nt_id, \"Unknown Term\") for nt_id in narrower_ids]\n",
    "    all_related_terms.extend(narrower_keywords)\n",
    "    \n",
    "    # Assign this collection of terms to the correct supergroup(s)\n",
    "    for sg_id in descriptor_to_supergroups.get(termid, []):\n",
    "        supergroup_all_terms[sg_id].extend(all_related_terms)\n",
    "\n",
    "# Write the collected data to the text file\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for sg_id, terms_list in supergroup_all_terms.items():\n",
    "        supergroup_name = supergroup_names.get(sg_id, \"Unknown Supergroup\")\n",
    "        \n",
    "        # Use a set to get unique terms, then join with a pipe\n",
    "        # This prevents the same term from appearing multiple times in a line\n",
    "        unique_terms = sorted(list(set(terms_list)))\n",
    "        line_content = \"|\".join(unique_terms)\n",
    "        \n",
    "        outfile.write(f\"{supergroup_name}:{line_content}\\n\")\n",
    "\n",
    "print(\"Done. The output has been saved to the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dcb92fe-ee17-4689-8a85-2ff190443ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "##This does recursive Dump of terms into a json\n",
    "\n",
    "\n",
    "from lxml import etree\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "#xml_file = \"your_input.xml\"  # Pfad zur XML-Datei\n",
    "LANG_ID_ENGLISH = \"1\"\n",
    "output_filename = \"thesaurus_supergroup_hierarchy_DE.json\"\n",
    "\n",
    "termid_to_keyword = {}\n",
    "supergroup_names = {}\n",
    "descriptor_to_supergroups = defaultdict(list)\n",
    "descriptor_narrower_terms = defaultdict(list)\n",
    "\n",
    "# --- Pass 1: Begriffe sammeln ---\n",
    "for _, elem in etree.iterparse(xml_file, events=(\"end\",), tag=\"DESCRIPTOR\"):\n",
    "    termid = elem.get(\"TERMID\")\n",
    "    langdata = elem.find(f\"LANGDATA[@LANGID='{LANG_ID_ENGLISH}']\")\n",
    "    if langdata is not None:\n",
    "        term_elem = langdata.find(\"TERM\")\n",
    "        if term_elem is not None and term_elem.text:\n",
    "            termid_to_keyword[termid] = term_elem.text.strip()\n",
    "    elem.clear()\n",
    "\n",
    "# --- Pass 2: Supergruppen-Namen sammeln ---\n",
    "for _, elem in etree.iterparse(xml_file, events=(\"end\",), tag=\"SUPERGROUP\"):\n",
    "    sg_id = elem.get(\"ID\")\n",
    "    lang_entry = elem.find(f\"LANGENTRY[@LANGID='{LANG_ID_ENGLISH}']\")\n",
    "    if lang_entry is not None:\n",
    "        designator = lang_entry.findtext(\"DESIGNATOR\")\n",
    "        if designator:\n",
    "            supergroup_names[sg_id] = designator.strip()\n",
    "    elem.clear()\n",
    "\n",
    "# --- Pass 3: Zuordnungen ---\n",
    "for _, elem in etree.iterparse(xml_file, events=(\"end\",), tag=\"DESCRIPTOR\"):\n",
    "    termid = elem.get(\"TERMID\")\n",
    "    for group_ptr in elem.findall(\"GROUPPTR\"):\n",
    "        if group_ptr.text:\n",
    "            descriptor_to_supergroups[termid].append(group_ptr.text.strip())\n",
    "    for nt_ptr in elem.findall(\"NTPTR\"):\n",
    "        if nt_ptr.text:\n",
    "            descriptor_narrower_terms[termid].append(nt_ptr.text.strip())\n",
    "    elem.clear()\n",
    "\n",
    "# --- Alle Narrower rekursiv aufl√∂sen ---\n",
    "def get_all_narrowers(termid, seen=None):\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    result = []\n",
    "    for child in descriptor_narrower_terms.get(termid, []):\n",
    "        if child in seen:\n",
    "            continue\n",
    "        seen.add(child)\n",
    "        if child in termid_to_keyword:\n",
    "            result.append(termid_to_keyword[child])\n",
    "        result.extend(get_all_narrowers(child, seen))\n",
    "    return result\n",
    "\n",
    "# --- IDs aller Narrower sammeln, um doppelte Top-Level zu verhindern ---\n",
    "all_narrower_ids = set()\n",
    "for nt_list in descriptor_narrower_terms.values():\n",
    "    all_narrower_ids.update(nt_list)\n",
    "\n",
    "# --- Hierarchie aufbauen ---\n",
    "supergroup_dict = defaultdict(dict)\n",
    "\n",
    "for termid, sg_ids in descriptor_to_supergroups.items():\n",
    "    if termid in all_narrower_ids:\n",
    "        continue  # auslassen, wenn der Begriff ein Narrower ist\n",
    "\n",
    "    descriptor = termid_to_keyword.get(termid, f\"Unknown descriptor {termid}\")\n",
    "    narrower = get_all_narrowers(termid)\n",
    "    if len(narrower) < 2:\n",
    "        continue\n",
    "    for sg_id in sg_ids:\n",
    "        sg_name = supergroup_names.get(sg_id, f\"Unknown Supergroup {sg_id}\")\n",
    "        supergroup_dict[sg_name][descriptor] = sorted(set(narrower))\n",
    "\n",
    "# --- Als JSON speichern ---\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(supergroup_dict, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
